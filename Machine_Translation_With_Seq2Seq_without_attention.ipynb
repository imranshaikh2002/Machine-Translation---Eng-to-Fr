{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeKtXt9V_NEP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_link = \"/content/fra-eng.zip\"\n",
        "zip_ref = zipfile.ZipFile(dataset_link)\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "TF0UjC_-AFKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def tokenize(texts):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "  return tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "E6yKqlEsAaMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link = \"/content/fra.txt\"\n",
        "en = []\n",
        "fr = []\n",
        "with open(link, \"r\") as f:\n",
        "  for line in f:\n",
        "    eng, fra, _ = line.strip().split('\\t')\n",
        "    en.append(eng)\n",
        "    fr.append(fra)"
      ],
      "metadata": {
        "id": "kICV5IALBX67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en"
      ],
      "metadata": {
        "id": "DRBF0d2UCN1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr"
      ],
      "metadata": {
        "id": "CcNYFem5CROS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "def data_cleaning(texts):\n",
        "\n",
        "  sents = []\n",
        "  for text in texts:\n",
        "    sent = text.lower()\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", sent)\n",
        "    sent = re.sub(r\"\\d+\", \"\", sent)\n",
        "    sents.append(sent)\n",
        "  return sents"
      ],
      "metadata": {
        "id": "L7PieqBxFv8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fra_sents(fra_sents):\n",
        "  fra_sents_in = []\n",
        "  fra_sents_out = []\n",
        "  for sent in fra_sents:\n",
        "    sent_in = \"BOS \" + sent\n",
        "    sent_out = sent + \" EOS\"\n",
        "    fra_sents_in.append(sent_in)\n",
        "    fra_sents_out.append(sent_out)\n",
        "\n",
        "  return fra_sents_in, fra_sents_out"
      ],
      "metadata": {
        "id": "l2Tmv4dHHFhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sent = data_cleaning(en)\n",
        "fra_sent = data_cleaning(fr)"
      ],
      "metadata": {
        "id": "l6j4fT_XLTan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sent"
      ],
      "metadata": {
        "id": "ZljU-2W9OAO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fra_sents_in, fra_sents_out = fra_sents(fra_sent)\n"
      ],
      "metadata": {
        "id": "A8XjUVGhODRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fra_sent[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RvTufFVVPAwX",
        "outputId": "64d597d4-1407-44ce-99c2-09c02303ef65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'va '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fra_sents_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKWeoqvfPDPL",
        "outputId": "c17e47ef-fece-4b4b-b57f-fcd36a38ba8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191954"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fra_sents_in[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MCJVOcC0PNb_",
        "outputId": "aaf1a72c-72d3-4ee4-a1bd-0fa96364da9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BOS va '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sent[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_4-ZyMC4PrN0",
        "outputId": "d79b5d2d-8678-434b-8228-4bc3e8ca2c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fra_sents_in[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OQU_HwMxQIaL",
        "outputId": "c6dd23ba-78d2-403e-df1e-a53c6dd4210f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BOS marche'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, maxlen, encoder_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.encoder_dim = encoder_dim\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)\n",
        "    self.rnn = tf.keras.layers.GRU(encoder_dim, return_sequences=False, return_state=True)\n",
        "\n",
        "  def call(self, x, state):\n",
        "    x = self.embedding(x)\n",
        "    x, state = self.rnn(x, initial_state=state)\n",
        "\n",
        "    return x, state\n",
        "\n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, self.encoder_dim))"
      ],
      "metadata": {
        "id": "si37hDrDPxlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, maxlen, decoder_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)\n",
        "    self.rnn = tf.keras.layers.GRU(decoder_dim, return_sequences=True, return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, state):\n",
        "    x = self.embedding(x)\n",
        "    x, state = self.rnn(x, state)\n",
        "    x = self.dense(x)\n",
        "\n",
        "    return x, state"
      ],
      "metadata": {
        "id": "kr-kN2giR5OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(ytrue, ypred):\n",
        "  scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  mask = tf.math.logical_not(tf.math.equal(ytrue, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  loss = scce(ytrue, ypred, sample_weight=mask)\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "c-PJjBYETDnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SENT_PAIRS = 30000\n",
        "EMBEDDING_DIM = 256\n",
        "ENCODER_DIM, DECODER_DIM = 1024, 1024\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 30"
      ],
      "metadata": {
        "id": "qtdKkFH8GCI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = tokenize(en_sent)\n",
        "tokenizer_fr = Tokenizer()\n",
        "tokenizer_fr.fit_on_texts(fra_sents_in)\n",
        "tokenizer_fr.fit_on_texts(fra_sents_out)"
      ],
      "metadata": {
        "id": "fpniXCmFFjPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_wordtoindex = tokenizer_en.word_index\n",
        "fr_wordtoindex = tokenizer_fr.word_index"
      ],
      "metadata": {
        "id": "8lcMRzINGwGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_wordtoindex"
      ],
      "metadata": {
        "id": "UPmUrtgnH7Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr_wordtoindex"
      ],
      "metadata": {
        "id": "1N4qQCSpIF2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_en = tokenizer_en.texts_to_sequences(en_sent)\n",
        "max_seq_len = max([len(w) for w in data_en])\n",
        "data_en = pad_sequences(data_en, maxlen = max_seq_len, padding=\"post\")\n",
        "\n",
        "data_fr_in = tokenizer_fr.texts_to_sequences(fra_sents_in)\n",
        "max_seq_len_fr_in = max([len(w) for w in data_fr_in])\n",
        "data_fr_in = pad_sequences(data_fr_in, maxlen = max_seq_len_fr_in, padding=\"post\")\n",
        "\n",
        "data_fr_out = tokenizer_fr.texts_to_sequences(fra_sents_out)\n",
        "max_seq_len_fr_out = max([len(w) for w in data_fr_out])\n",
        "data_fr_out = pad_sequences(data_fr_out, maxlen = max_seq_len_fr_out, padding=\"post\")\n"
      ],
      "metadata": {
        "id": "IcVgPPLMINde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXcKa7oJwcM",
        "outputId": "f82ea442-81a7-4f6a-bab9-1c228aa29d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   42,     0,     0, ...,     0,     0,     0],\n",
              "       [   42,     0,     0, ...,     0,     0,     0],\n",
              "       [   42,     0,     0, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  376,    55,    22, ...,     0,     0,     0],\n",
              "       [   64,   292,    78, ...,     0,     0,     0],\n",
              "       [   12,   174,    26, ...,     3, 10182,  3415]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_fr_in"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-7vO3uQJ0qb",
        "outputId": "1b07d307-01bc-4a27-f68c-3e6457fa847d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  112,    0, ...,    0,    0,    0],\n",
              "       [   1,  818,    0, ...,    0,    0,    0],\n",
              "       [   1, 2544,    0, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1, 8763,   48, ...,    0,    0,    0],\n",
              "       [   1,   43,  158, ...,   15, 2916, 2594],\n",
              "       [   1,   13,   14, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_fr_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzkOG0AdJ3ev",
        "outputId": "e7146685-8d09-4511-97de-898441e1c7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 112,    2,    0, ...,    0,    0,    0],\n",
              "       [ 818,    2,    0, ...,    0,    0,    0],\n",
              "       [2544,    2,    0, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [8763,   48,   11, ...,    0,    0,    0],\n",
              "       [  43,  158,   32, ..., 2916, 2594,    2],\n",
              "       [  13,   14,  265, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = BATCH_SIZE\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data_en, data_fr_in, data_fr_out))\n",
        "dataset = dataset.shuffle(10000)\n",
        "test_size = NUM_SENT_PAIRS // 4\n",
        "test_dataset = dataset.take(test_size).batch(batch_size, drop_remainder=True)\n",
        "train_dataset = dataset.skip(test_size).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "FOIx-92xJ7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_6Rab6oKJoL",
        "outputId": "6d721592-d863-4f22-d9b8-282122156d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 47), dtype=tf.int32, name=None), TensorSpec(shape=(64, 55), dtype=tf.int32, name=None), TensorSpec(shape=(64, 55), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = EMBEDDING_DIM\n",
        "encoder_dim, decoder_dim = ENCODER_DIM, DECODER_DIM"
      ],
      "metadata": {
        "id": "nny_3d8hKMpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_en = len(en_wordtoindex) + 1\n",
        "vocab_size_fr = len(fr_wordtoindex) + 1"
      ],
      "metadata": {
        "id": "ikaV8VajKdoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZNItroHK1qs",
        "outputId": "6bb5b5d1-09b3-4e96-c5b1-de08d8ea409d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_seq_len_fr_in)\n",
        "print(max_seq_len_fr_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvg-aVczK5Dt",
        "outputId": "934d2b67-7944-4a0d-88a9-397ae23376c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n",
            "55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_size_en, embedding_dim, max_seq_len, encoder_dim)\n",
        "decoder = Decoder(vocab_size_fr, embedding_dim, max_seq_len_fr_in, decoder_dim)"
      ],
      "metadata": {
        "id": "NLx9QYqtKp5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def train_step(encoder_in, decoder_in, decoder_out, encoder_state):\n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
        "    decoder_state = encoder_state\n",
        "    decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
        "    loss = loss_fn(decoder_out, decoder_pred)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradient = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradient, variables))\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "W4v08lC5TqWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indtoword_en = tokenizer_en.index_word\n",
        "indtoword_fr = tokenizer_fr.index_word"
      ],
      "metadata": {
        "id": "0-y-2Qb4K_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(encoder, decoder, batch_size, en_sent, data_en, fra_sents_out, word2idx_fr, idx2word_fr):\n",
        "  random_id = np.random.choice(len(en_sent))\n",
        "\n",
        "  encoder_in = tf.expand_dims(data_en[random_id], axis=0)\n",
        "  decoder_out = tf.expand_dims(fra_sents_out[random_id], axis=0)\n",
        "\n",
        "  encoder_state = encoder.init_state(1)\n",
        "  encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
        "  decoder_state = encoder_state\n",
        "  decoder_in = tf.expand_dims(\n",
        "        tf.constant([word2idx_fr[\"bos\"]]), axis=0)\n",
        "  pred_sent_fr = []\n",
        "\n",
        "  while(True):\n",
        "    decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
        "    decoder_pred_index = tf.argmax(decoder_pred, axis = -1)\n",
        "    pred_word = idx2word_fr[decoder_pred_index.numpy()[0][0]]\n",
        "\n",
        "    pred_sent_fr.append(pred_word)\n",
        "    if pred_word == \"eos\":\n",
        "        break\n",
        "\n",
        "    decoder_in = decoder_pred_index\n",
        "\n",
        "  print(\"predicted: \", \" \".join(pred_sent_fr))"
      ],
      "metadata": {
        "id": "6l-bLCbpNRfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  encoder_state = encoder.init_state(batch_size)\n",
        "\n",
        "  for batch, data in enumerate(train_dataset):\n",
        "    encoder_in, decoder_in, decoder_out = data\n",
        "\n",
        "    loss = train_step(encoder_in, decoder_in, decoder_out, encoder_state)\n",
        "\n",
        "  predict(encoder, decoder, batch_size, en_sent, data_en, fra_sents_out, fr_wordtoindex, indtoword_fr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRzmWXmlQmcS",
        "outputId": "ffed58fe-ce33-4572-e2a4-620ddef752d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted:  je veux me lever tt le matin suivant eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fr_wordtoindex"
      ],
      "metadata": {
        "id": "pSJaQZlsRxTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZlIitFNWY4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}